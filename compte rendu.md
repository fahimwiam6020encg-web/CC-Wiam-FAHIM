# üìò Rapport d‚ÄôAnalyse ‚Äì D√©tection de Fraude

## 1. Introduction

La d√©tection de fraude repr√©sente aujourd‚Äôhui un enjeu strat√©gique pour les institutions financi√®res, les plateformes de paiement et les services en ligne. Les transactions frauduleuses, bien que minoritaires, entra√Ænent des pertes √©conomiques consid√©rables et n√©cessitent des syst√®mes robustes et automatis√©s capables de les identifier efficacement.


---

## 2. Analyse et D√©veloppement

### 2.1 Analyse des donn√©es

#### 2.1.1 D√©s√©quilibre de la variable cible

L'exploration initiale montre un **d√©s√©quilibre important** entre les transactions l√©gitimes et frauduleuses.  
Les fraudes constituent une **faible minorit√©**, ce qui rend le probl√®me difficile √† traiter :

- Un mod√®le na√Øf pourrait pr√©dire "non frauduleux" pour toutes les transactions et obtenir une *accuracy √©lev√©e*.
- Les m√©triques comme l‚Äô**accuracy** deviennent trompeuses dans ce contexte.

‚û°Ô∏è Il est donc n√©cessaire de compl√©ter l‚Äôanalyse avec des mesures comme la **precision**, le **recall**, le **F1-score** et la **matrice de confusion**.

#### 2.1.2 Corr√©lation entre les variables

La heatmap de corr√©lation met en √©vidence :

- Des relations mod√©r√©es entre certaines caract√©ristiques et la variable cible.
- Des corr√©lations fortes entre certaines variables explicatives, pouvant introduire de la redondance.
- Une n√©cessit√© possible de r√©duire ou transformer les variables fortement corr√©l√©es.

L'ajout des variables temporelles (*mois*, *ann√©e*) am√©liore la compr√©hension des comportements inhabituels li√©s √† la fraude.

#### 2.1.3 Pr√©traitement et cr√©ation de nouvelles variables

Le notebook inclut :
- une extraction d'informations depuis les dates,  
- un nettoyage basique des donn√©es,  
- une pr√©paration des features pour la mod√©lisation.

L‚Äôenrichissement des donn√©es contribue √† am√©liorer la capacit√© du mod√®le √† d√©tecter des anomalies.

---

### 2.2 Mod√©lisation : Random Forest

Le mod√®le utilis√© est un **Random Forest Classifier**, pertinent pour ce type de probl√®me en raison de sa robustesse et de sa capacit√© √† g√©rer :

- des donn√©es num√©riques et cat√©gorielles (apr√®s encodage),
- des relations non lin√©aires,
- une importance variable des caract√©ristiques.

Le dataset est divis√© selon un ratio :
- **70%** pour l‚Äôentra√Ænement,
- **30%** pour le test.

Aucun tuning avanc√© n‚Äôest appliqu√© dans le notebook initial, ce qui fait du mod√®le une bonne base de r√©f√©rence.

---

### 2.3 R√©sultats obtenus et interpr√©tation

#### 2.3.1 Accuracy

Bien que l‚Äô**accuracy soit √©lev√©e**, elle est insuffisante pour √©valuer r√©ellement la performance du mod√®le en raison du d√©s√©quilibre du dataset.

‚û°Ô∏è L‚Äôaccuracy seule **ne refl√®te pas** la capacit√© √† d√©tecter les fraudes.

#### 2.3.2 Matrice de confusion

La matrice de confusion r√©v√®le :

- **TN (vrais n√©gatifs)** √©lev√©s ‚Üí le mod√®le identifie correctement les transactions normales.
- **TP (vrais positifs)** pr√©sents ‚Üí le mod√®le d√©tecte une partie des fraudes.
- **FP (faux positifs)** mod√©r√©s ‚Üí certains comportements l√©gitimes sont signal√©s par erreur.
- **FN (faux n√©gatifs)** encore trop nombreux ‚Üí certaines fraudes ne sont pas capt√©es.

‚û°Ô∏è Les **faux n√©gatifs** constituent le principal probl√®me car ils repr√©sentent des fraudes r√©elles non d√©tect√©es.

#### 2.3.3 Interpr√©tation avanc√©e

- Le **recall** (capacit√© √† d√©tecter les fraudes) n‚Äôest pas maximal.
- La **precision** est correcte : les fraudes identifi√©es sont bien d√©tect√©es.
- Le **F1-score** indique un compromis moyen entre precision et recall.

L‚Äôanalyse montre que le mod√®le a une **bonne base**, mais qu‚Äôil n√©cessite des am√©liorations pour r√©duire les faux n√©gatifs.

#### 2.3.4 Importance des caract√©ristiques

Le Random Forest met en avant plusieurs variables cl√©s :

- montant de la transaction,  
- fr√©quence des op√©rations,  
- caract√©ristiques temporelles,  
- certains profils clients.

Cette importance des features contribue √† expliquer les d√©cisions du mod√®le et peut orienter les futures optimisations.

---<img width="652" height="540" alt="t√©l√©chargement (1)" src="https://github.com/user-attachments/assets/28c9c07d-ae53-48db-a591-c164db695bb1" />


## 3. Limites du mod√®le actuel

Plusieurs limites ressortent de l‚Äôanalyse :

1. **D√©s√©quilibre marqu√© des classes** ‚Üí fausses non-d√©tections.
2. **Absence de tuning** des hyperparam√®tres du mod√®le.
3. **M√©triques limit√©es** dans la version initiale du notebook.
4. **Un seul mod√®le test√©**, pas de comparaison avec d‚Äôautres algorithmes performants (XGBoost, LightGBM).
5. **Pas de traitement avanc√© du d√©s√©quilibre** (SMOTE, class_weight).

Ces limites expliquent la performance imparfaite, surtout pour la classe minoritaire.

---<img width="887" height="540" alt="t√©l√©chargement" src="https://github.com/user-attachments/assets/24030eb6-b42f-4450-8b5c-27dd0cf05029" />


## 4. Conclusion

Le mod√®le d√©velopp√© dans le notebook constitue une **premi√®re version solide** pour une d√©tection automatique de fraude.  
Il parvient √† :

- bien classifier les transactions normales,
- d√©tecter une partie significative des fraudes,
- exploiter efficacement les caract√©ristiques disponibles.

Cependant, des am√©liorations sont n√©cessaires pour obtenir des r√©sultats professionnels :

- gestion du d√©s√©quilibre via SMOTE ou *class_weight*,
- optimisation des hyperpa
